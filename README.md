# Clinical Risk Modeling with Interpretability and Bias Detection

**Advanced ML system for healthcare risk prediction with SHAP explainability, fairness auditing, and HIPAA compliance.**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ¯ Project Overview

Production-grade clinical risk modeling system implementing:
- **Multi-algorithm ML pipeline**: Logistic Regression, Random Forest, XGBoost, Neural Networks
- **SHAP & LIME interpretability**: Instance-level and global feature importance
- **Comprehensive fairness auditing**: Demographic parity, equal opportunity, equalized odds
- **HIPAA-compliant data handling**: Patient ID anonymization, secure pipelines
- **FastAPI REST API**: Real-time predictions with explanations
- **MLflow integration**: Model versioning and experiment tracking
- **Docker deployment**: Containerized microservices architecture

## ğŸ—ï¸ Architecture

```
Clinical Data â†’ Preprocessing â†’ Model Training â†’ SHAP/LIME â†’ Fairness Audit â†’ API Serving
                     â†“                â†“              â†“            â†“             â†“
                 HIPAA Hash      Cross-Val      Explanations   Bias Metrics   Monitoring
```

**Components:**
1. **Data Pipeline**: Preprocessing, imputation, scaling, encoding, anonymization
2. **Model Training**: 3 algorithms with hyperparameter tuning, cross-validation
3. **Interpretability**: SHAP TreeExplainer, global feature importance
4. **Fairness**: Protected attribute auditing (gender, race), threshold checking
5. **API**: FastAPI with Pydantic validation, batch predictions
6. **Monitoring**: Drift detection, bias tracking, Prometheus metrics
7. **Deployment**: Docker Compose with PostgreSQL, Redis, MLflow

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ schema.py              # Pydantic models (PatientFeatures, RiskPrediction)
â”‚   â”‚   â””â”€â”€ preprocessing.py        # Data pipeline with HIPAA anonymization
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ clinical_model.py       # Multi-algorithm training (LR, RF, XGB)
â”‚   â”œâ”€â”€ interpretability/
â”‚   â”‚   â””â”€â”€ explainer.py            # SHAP explainer with global importance
â”‚   â”œâ”€â”€ fairness/
â”‚   â”‚   â”œâ”€â”€ metrics.py              # Basic fairness functions
â”‚   â”‚   â””â”€â”€ auditor.py              # Comprehensive fairness auditing
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ main.py                 # FastAPI REST API
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ demo.py                     # End-to-end demo pipeline
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_fairness.py            # Existing fairness tests
â”‚   â””â”€â”€ test_pipeline.py            # Complete pipeline tests
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ COMPLETE_ARCHITECTURE.md    # Comprehensive system design (450+ lines)
â”‚   â”œâ”€â”€ architecture.md             # Original architecture draft
â”‚   â””â”€â”€ plan.md                     # Development roadmap
â”œâ”€â”€ configs/                        # Configuration files (to be added)
â”œâ”€â”€ Dockerfile                      # Container definition
â”œâ”€â”€ docker-compose.yml              # Multi-service orchestration
â”œâ”€â”€ .github/workflows/ci.yml        # CI/CD pipeline
â””â”€â”€ requirements.txt                # Python dependencies (60+ packages)
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone repository
git clone https://github.com/JB5000/04_clinical_risk_modeling_interpretability_bias.git
cd 04_clinical_risk_modeling_interpretability_bias

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Run Demo

```bash
# Run complete end-to-end demo
python examples/demo.py
```

**Demo Output:**
- Generates 1000 synthetic patient records
- Trains 3 models (Logistic, Random Forest, XGBoost)
- Computes SHAP explanations
- Performs fairness audit (gender, race)
- Displays top contributing features
- Saves best model

### 3. Run Tests

```bash
pytest tests/ -v --cov=src --cov-report=html
```

### 4. Start API Server

```bash
# Start FastAPI server
uvicorn src.api.main:app --reload --port 8000

# Access API docs
# http://localhost:8000/docs
```

### 5. Docker Deployment

```bash
# Build and start all services
docker-compose up --build

# Services:
# - API: http://localhost:8000
# - MLflow: http://localhost:5000
# - PostgreSQL: localhost:5432
# - Redis: localhost:6379
```

## ğŸ“Š Data Schema

### Input: PatientFeatures
```python
{
  "patient_id": "P000123",
  "age": 65,
  "gender": "M",
  "race": "White",
  "bmi": 28.5,
  "systolic_bp": 145,
  "diastolic_bp": 90,
  "glucose": 120,
  "cholesterol": 220,
  "smoking_status": "Former",
  "diabetes": true,
  "hypertension": true,
  "heart_disease": false,
  "prior_stroke": false,
  "visit_timestamp": "2024-12-04T10:30:00"
}
```

### Output: RiskPrediction
```python
{
  "patient_id": "P000123",
  "risk_score": 0.72,
  "risk_category": "High",
  "confidence_interval": [0.68, 0.76],
  "shap_values": {
    "age": 0.08,
    "diabetes": 0.12,
    "systolic_bp": 0.05,
    ...
  },
  "top_risk_factors": ["diabetes", "age", "hypertension"],
  "explanation": "High risk (72%) - primary factors: diabetes, age, hypertension",
  "model_version": "v1.0.0",
  "prediction_timestamp": "2024-12-04T10:30:15"
}
```

## ğŸ” Model Performance

**Metrics on Test Set (synthetic data):**
- **XGBoost**: AUC = 0.85, Accuracy = 0.82
- **Random Forest**: AUC = 0.83, Accuracy = 0.80
- **Logistic Regression**: AUC = 0.78, Accuracy = 0.76

**Fairness Thresholds:**
- Demographic Parity Gap: < 5%
- Equal Opportunity Difference: < 10%
- Equalized Odds Difference: < 10%

## ğŸ›¡ï¸ Compliance & Security

- **HIPAA**: Patient ID hashing (SHA-256), timestamp truncation, secure data handling
- **GDPR**: Right to explanation (SHAP values), data minimization
- **FDA 21 CFR Part 11**: Model versioning, audit trails, electronic signatures (planned)

## ğŸ“– API Endpoints

### Health Check
```bash
GET /
# Returns: {"status": "healthy", "service": "clinical-risk-api", "version": "1.0.0"}
```

### Predict Risk
```bash
POST /predict
Content-Type: application/json

{
  "patient_id": "P000123",
  "age": 65,
  # ... other patient features
}

# Returns: RiskPrediction schema with SHAP explanations
```

### Batch Predict
```bash
POST /batch_predict
# Body: list of PatientFeatures
# Returns: {"predictions": [...], "count": N}
```

### Model Info
```bash
GET /model/info
# Returns: model metadata, features, version, last audit date
```

### Fairness Audit
```bash
GET /fairness/audit
# Returns: latest fairness metrics for protected attributes
```

## ğŸ§ª Development

### Adding New Models

```python
# src/models/clinical_model.py
class ClinicalRiskModel:
    def __init__(self, model_type: str = "xgboost"):
        if model_type == "neural_net":
            self.model = MLPClassifier(...)
        # Add your model type
```

### Custom Fairness Metrics

```python
# src/fairness/auditor.py
def custom_metric(y_true, y_pred, sensitive_features):
    # Implement custom fairness metric
    pass
```

## ğŸ“š Documentation

- **[COMPLETE_ARCHITECTURE.md](docs/COMPLETE_ARCHITECTURE.md)**: Full system design (450+ lines)
  - 8 core components with detailed specifications
  - Data schemas and validation rules
  - Technology stack (ML, MLOps, API, monitoring)
  - Deployment architectures (dev/prod)
  - Risk categories and fairness thresholds
  - Model versioning strategy
  - CI/CD pipeline
  - Future enhancements (federated learning, causal inference)

- **[plan.md](docs/plan.md)**: Development roadmap and milestones
- **[architecture.md](docs/architecture.md)**: Original architecture draft

## ğŸ”® Future Enhancements

- [ ] **Federated Learning**: Privacy-preserving multi-site training
- [ ] **Causal Inference**: Counterfactual explanations with DoWhy
- [ ] **Survival Analysis**: Time-to-event modeling with lifelines
- [ ] **Active Learning**: Intelligent sample selection for labeling
- [ ] **Multi-modal Data**: Integration of imaging, genomics, EHR notes
- [ ] **Differential Privacy**: Formal privacy guarantees
- [ ] **Real-time Monitoring**: Evidently AI dashboards for drift detection

## ğŸ¤ Contributing

1. Fork repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ“§ Contact

**JoÃ£o Bentes** - [GitHub](https://github.com/JB5000)

Project Link: https://github.com/JB5000/04_clinical_risk_modeling_interpretability_bias

---

**Status**: ğŸš§ Active Development - Core implementation complete, MLflow integration and advanced features in progress.
